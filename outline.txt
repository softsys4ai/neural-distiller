// train all teacher models that are not pre-trained
// load each teacher model configurations and weights
// create a directory for each run of the program to contain all of the saved metrics and student models
// REFERENCE POINT 1
// perform five different pruning techniques to the teacher network
// save each pruned teacher model as a new student model within a directory named by the iteration number
// modify the student network to accept and produce the correct output
// tune each student model by training it for 100 epochs on hard and soft teacher targets
// compare and rank all of the models with accuracy and validation_accuracy weighed 1:3
// save the rankings of student models and their associated pruning method
// choose the best performing student model and load it
// modify this student model to output in the correct dimensions (original nb_classes)
// decrease the temperature value by 5
// return to REFERENCE POINT 1
// repeat this process 10 times
